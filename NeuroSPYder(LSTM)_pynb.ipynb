{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPrMhBarOCyvs7aCW02iDWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polydeuces32/s-p500-predicter-on-Python-/blob/main/NeuroSPYder(LSTM)_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mFzgu9vft-uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“Š What Youâ€™ll Get:\n",
        "Sharpe Ratio ðŸ“ˆ\n",
        "\n",
        "Max Drawdown ðŸ“‰\n",
        "\n",
        "Final Balance ðŸ’°\n",
        "\n",
        "Trade Log Table **ðŸ§¾**"
      ],
      "metadata": {
        "id": "6XbGWGlMuNXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-run everything after code execution reset\n",
        "\n",
        "# Step 1: Install Required Libraries\n",
        "!pip install yfinance tensorflow scikit-learn matplotlib --quiet\n"
      ],
      "metadata": {
        "id": "2eNFXk5CR3ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Step 1: Download SPY Data\n",
        "data = yf.download('SPY', start='2018-01-01', interval='1d')[['Close']]\n",
        "data['Close'] = data['Close'].ffill()\n",
        "\n",
        "# Step 2: Add Rolling Volatility\n",
        "data['Volatility'] = data['Close'].rolling(window=10).std()\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Step 3: Normalize Prices\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
        "\n",
        "# Step 4: Prepare Sequences\n",
        "sequence_length = 60\n",
        "X, y = [], []\n",
        "for i in range(sequence_length, len(scaled_data) - 1):\n",
        "    X.append(scaled_data[i - sequence_length:i, 0])\n",
        "    y.append(scaled_data[i + 1, 0])\n",
        "X, y = np.array(X), np.array(y)\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Step 5: Build the LSTM Model\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(units=64, return_sequences=True, input_shape=(X.shape[1], 1))),\n",
        "    Dropout(0.3),\n",
        "    BatchNormalization(),\n",
        "    LSTM(units=64, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    BatchNormalization(),\n",
        "    LSTM(units=32),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=16, activation='relu'),\n",
        "    Dense(units=1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 6: Train Model\n",
        "model.fit(X, y, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Step 7: Backtesting with Dynamic TP/SL\n",
        "initial_balance = 5000\n",
        "balance = initial_balance\n",
        "positions = []\n",
        "returns = []\n",
        "\n",
        "close_prices = data['Close'].values\n",
        "volatilities = data['Volatility'].values\n",
        "predicted_prices = []\n",
        "\n",
        "for i in range(sequence_length, len(close_prices) - 1):\n",
        "    current_sequence = scaled_data[i - sequence_length:i].reshape(1, sequence_length, 1)\n",
        "    predicted_scaled = model.predict(current_sequence, verbose=0)\n",
        "    predicted_price = scaler.inverse_transform(predicted_scaled)[0][0]\n",
        "    predicted_prices.append(predicted_price)\n",
        "\n",
        "    entry_price = close_prices[i]\n",
        "    next_day_price = close_prices[i + 1]\n",
        "    shares = balance / entry_price\n",
        "    volatility = volatilities[i]\n",
        "\n",
        "    take_profit_price = entry_price * (1 + 1.5 * volatility / entry_price)\n",
        "    stop_loss_price = entry_price * (1 - 1.0 * volatility / entry_price)\n",
        "\n",
        "    if predicted_price > entry_price:\n",
        "        if next_day_price >= take_profit_price:\n",
        "            exit_price = take_profit_price\n",
        "        elif next_day_price <= stop_loss_price:\n",
        "            exit_price = stop_loss_price\n",
        "        else:\n",
        "            exit_price = next_day_price\n",
        "\n",
        "        pnl = (exit_price - entry_price) * shares\n",
        "        balance += pnl\n",
        "        returns.append(float(balance))\n",
        "        positions.append((entry_price, exit_price, pnl))\n",
        "\n",
        "# Step 8: Performance Metrics\n",
        "returns_series = pd.Series([float(r) for r in returns])\n",
        "daily_returns = returns_series.pct_change().dropna()\n",
        "\n",
        "if not daily_returns.empty:\n",
        "    sharpe_ratio = daily_returns.mean() / daily_returns.std() * np.sqrt(252)\n",
        "else:\n",
        "    sharpe_ratio = 0.0\n",
        "\n",
        "cumulative = returns_series\n",
        "rolling_max = cumulative.cummax()\n",
        "drawdown = (cumulative - rolling_max) / rolling_max\n",
        "max_drawdown = drawdown.min()\n",
        "\n",
        "# Step 9: Display Results\n",
        "backtest_df = pd.DataFrame(positions, columns=[\"Entry\", \"Exit\", \"PnL\"])\n",
        "backtest_df_tail = backtest_df.tail()\n",
        "\n",
        "# Save CSV (Optional)\n",
        "backtest_df.to_csv(\"NeuroSPYder_Backtest_Results.csv\", index=False)\n",
        "\n",
        "# Plot Equity Curve\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(returns_series.values, label=\"Portfolio Value\")\n",
        "plt.title(\"ðŸ“ˆ Equity Curve - NeuroSPYder\")\n",
        "plt.xlabel(\"Trades\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot Drawdown\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(drawdown.values, label=\"Drawdown\", color='red')\n",
        "plt.title(\"ðŸ“‰ Drawdown Curve - NeuroSPYder\")\n",
        "plt.xlabel(\"Trades\")\n",
        "plt.ylabel(\"Drawdown %\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Show final metrics and last trades\n",
        "(sharpe_ratio, max_drawdown, balance), backtest_df_tail\n"
      ],
      "metadata": {
        "id": "KqM92AeCR8iC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}