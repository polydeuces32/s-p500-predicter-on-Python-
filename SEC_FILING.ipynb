{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPM6b8mLfN9SoEuZOW66v16",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polydeuces32/s-p500-predicter-on-Python-/blob/main/SEC_FILING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# SEC EDGAR base URL\n",
        "base_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
        "\n",
        "# SEC requires a custom User-Agent header\n",
        "headers = {\n",
        "    \"User-Agent\": \"GiancarloVizhnay contact@example.com\",  # <-- use your name/email\n",
        "    \"Accept-Encoding\": \"gzip, deflate\",\n",
        "    \"Host\": \"www.sec.gov\"\n",
        "}\n",
        "\n",
        "# Choose forms and how many days back to search\n",
        "forms_to_track = [\"4\", \"S-1\"]  # Form 4 (insider) and S-1 (IPOs)\n",
        "days_back = 10\n",
        "\n",
        "results = []\n",
        "\n",
        "for form in forms_to_track:\n",
        "    for day in range(days_back):\n",
        "        target_date = (datetime.today() - timedelta(days=day)).strftime(\"%Y%m%d\")\n",
        "        print(f\"ðŸ” Checking {form} filings on {target_date}...\")\n",
        "\n",
        "        params = {\n",
        "            \"action\": \"getcurrent\",\n",
        "            \"datea\": target_date,\n",
        "            \"type\": form,\n",
        "            \"owner\": \"include\",\n",
        "            \"count\": \"100\"\n",
        "        }\n",
        "\n",
        "        response = requests.get(base_url, headers=headers, params=params)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        rows = soup.find_all(\"tr\")[1:]  # Skip header row\n",
        "\n",
        "        for row in rows:\n",
        "            cols = row.find_all(\"td\")\n",
        "            if len(cols) < 4:\n",
        "                continue\n",
        "            company = cols[0].text.strip()\n",
        "            form_type = cols[1].text.strip()\n",
        "            cik = cols[2].text.strip()\n",
        "            date_filed = cols[3].text.strip()\n",
        "            link_tag = cols[1].find(\"a\")\n",
        "            if link_tag:\n",
        "                doc_link = \"https://www.sec.gov\" + link_tag.get(\"href\").strip()\n",
        "            else:\n",
        "                doc_link = None\n",
        "\n",
        "            results.append({\n",
        "                \"Date\": date_filed,\n",
        "                \"Company\": company,\n",
        "                \"CIK\": cik,\n",
        "                \"Form Type\": form_type,\n",
        "                \"Link\": doc_link\n",
        "            })\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "df = df.sort_values(by=\"Date\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Display first 15 filings\n",
        "import IPython\n",
        "from IPython.display import display\n",
        "display(df.head(15))\n"
      ],
      "metadata": {
        "id": "Y6-SpI9GdOb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# EDGAR URL and headers\n",
        "base_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"GiancarloVizhnay contact@example.com\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate\",\n",
        "    \"Host\": \"www.sec.gov\"\n",
        "}\n",
        "\n",
        "# CONFIG\n",
        "form_filter = \"S-1\"   # Choose \"4\" for Insider Trades, \"S-1\" for IPOs\n",
        "days_back = 5         # How many days back to scrape\n",
        "keywords = [\"bio\", \"tech\"]  # Filter by these words in company names\n",
        "\n",
        "results = []\n",
        "\n",
        "for day in range(days_back):\n",
        "    target_date = (datetime.today() - timedelta(days=day)).strftime(\"%Y%m%d\")\n",
        "    print(f\"ðŸ” Scraping {form_filter} filings on {target_date}...\")\n",
        "\n",
        "    params = {\n",
        "        \"action\": \"getcurrent\",\n",
        "        \"datea\": target_date,\n",
        "        \"type\": form_filter,\n",
        "        \"owner\": \"include\",\n",
        "        \"count\": \"100\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, headers=headers, params=params)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    rows = soup.find_all(\"tr\")[1:]\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(\"td\")\n",
        "        if len(cols) < 4:\n",
        "            continue\n",
        "\n",
        "        company = cols[0].text.strip()\n",
        "        form_type = cols[1].text.strip()\n",
        "        cik = cols[2].text.strip()\n",
        "        date_filed = cols[3].text.strip()\n",
        "        link_tag = cols[1].find(\"a\")\n",
        "        doc_link = f\"https://www.sec.gov{link_tag['href'].strip()}\" if link_tag else None\n",
        "\n",
        "        # Filter by keyword in company name\n",
        "        if any(kw.lower() in company.lower() for kw in keywords):\n",
        "            results.append({\n",
        "                \"Company Name\": company,\n",
        "                \"Form Type\": form_type,\n",
        "                \"CIK\": cik,\n",
        "                \"Date Filed\": date_filed,\n",
        "                \"Link to Filing\": doc_link\n",
        "            })\n",
        "\n",
        "# Safely create DataFrame and display\n",
        "if results:\n",
        "    df = pd.DataFrame(results)\n",
        "    df = df.sort_values(\"Date Filed\", ascending=False).reset_index(drop=True)\n",
        "    pd.set_option(\"display.max_colwidth\", None)\n",
        "    display(df.head(15))\n",
        "else:\n",
        "    print(\"ðŸš« No matching filings found with keywords:\", \", \".join(keywords))\n"
      ],
      "metadata": {
        "id": "71DbRH4ve9Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# EDGAR config\n",
        "base_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"GiancarloVizhnay contact@example.com\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate\",\n",
        "    \"Host\": \"www.sec.gov\"\n",
        "}\n",
        "\n",
        "# ðŸ“Œ CONFIG\n",
        "form_filter = \"S-1\"    # Choose \"4\" for Insider Trades, \"S-1\" for IPOs\n",
        "days_back = 5          # How many days to go back\n",
        "keywords = []          # e.g., [\"bio\", \"tech\"], leave empty to show ALL\n",
        "\n",
        "results = []\n",
        "\n",
        "# Scrape loop\n",
        "for day in range(days_back):\n",
        "    target_date = (datetime.today() - timedelta(days=day)).strftime(\"%Y%m%d\")\n",
        "    print(f\"ðŸ” Scraping {form_filter} filings on {target_date}...\")\n",
        "\n",
        "    params = {\n",
        "        \"action\": \"getcurrent\",\n",
        "        \"datea\": target_date,\n",
        "        \"type\": form_filter,\n",
        "        \"owner\": \"include\",\n",
        "        \"count\": \"100\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, headers=headers, params=params)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    rows = soup.find_all(\"tr\")[1:]  # Skip header\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(\"td\")\n",
        "        if len(cols) < 4:\n",
        "            continue\n",
        "\n",
        "        company = cols[0].text.strip()\n",
        "        form_type = cols[1].text.strip()\n",
        "        cik = cols[2].text.strip()\n",
        "        date_filed = cols[3].text.strip()\n",
        "        link_tag = cols[1].find(\"a\")\n",
        "        doc_link = f\"https://www.sec.gov{link_tag['href'].strip()}\" if link_tag else None\n",
        "\n",
        "        # Only filter if keywords are specified\n",
        "        if keywords:\n",
        "            if not any(kw.lower() in company.lower() for kw in keywords):\n",
        "                continue\n",
        "\n",
        "        results.append({\n",
        "            \"Company Name\": company,\n",
        "            \"Form Type\": form_type,\n",
        "            \"CIK\": cik,\n",
        "            \"Date Filed\": date_filed,\n",
        "            \"Link to Filing\": doc_link\n",
        "        })\n",
        "\n",
        "# Output result\n",
        "if results:\n",
        "    df = pd.DataFrame(results)\n",
        "    df = df.sort_values(\"Date Filed\", ascending=False).reset_index(drop=True)\n",
        "    pd.set_option(\"display.max_colwidth\", None)\n",
        "    display(df.head(20))\n",
        "else:\n",
        "    msg = f\"No matching filings found for Form {form_filter}\"\n",
        "    if keywords:\n",
        "        msg += \" with keywords: \" + \", \".join(keywords)\n",
        "    print(\"ðŸš«\", msg)\n"
      ],
      "metadata": {
        "id": "yPmTMsfnftx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# EDGAR setup\n",
        "base_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"GiancarloVizhnay contact@example.com\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate\",\n",
        "    \"Host\": \"www.sec.gov\"\n",
        "}\n",
        "\n",
        "# ðŸŽ›ï¸ Settings\n",
        "form_filter = \"4\"    # \"S-1\" for IPOs, \"4\" for insider buys/sells\n",
        "days_back = 10          # Look back this many days\n",
        "keywords = []          # e.g., [\"tech\", \"bio\"], leave empty to get everything\n",
        "\n",
        "# ðŸ—‚ï¸ Where we store what we find\n",
        "results = []\n",
        "\n",
        "# ðŸ•µï¸ Loop through recent days\n",
        "for day in range(days_back):\n",
        "    date_str = (datetime.today() - timedelta(days=day)).strftime(\"%Y%m%d\")\n",
        "    print(f\"ðŸ“… Looking at {form_filter} filings from {date_str}...\")\n",
        "\n",
        "    params = {\n",
        "        \"action\": \"getcurrent\",\n",
        "        \"datea\": date_str,\n",
        "        \"type\": form_filter,\n",
        "        \"owner\": \"include\",\n",
        "        \"count\": \"100\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, headers=headers, params=params)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    rows = soup.find_all(\"tr\")[1:]\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(\"td\")\n",
        "        if len(cols) < 4:\n",
        "            continue\n",
        "\n",
        "        company = cols[0].text.strip()\n",
        "        form_type = cols[1].text.strip()\n",
        "        cik = cols[2].text.strip()\n",
        "        filed = cols[3].text.strip()\n",
        "        link_tag = cols[1].find(\"a\")\n",
        "        doc_link = f\"https://www.sec.gov{link_tag['href'].strip()}\" if link_tag else None\n",
        "\n",
        "        # Only filter if keywords exist\n",
        "        if keywords:\n",
        "            if not any(kw.lower() in company.lower() for kw in keywords):\n",
        "                continue\n",
        "\n",
        "        results.append({\n",
        "            \"ðŸ§¾ Company\": company,\n",
        "            \"ðŸ“„ Form\": form_type,\n",
        "            \"ðŸ†” CIK\": cik,\n",
        "            \"ðŸ“… Date Filed\": filed,\n",
        "            \"ðŸ”— Link\": doc_link\n",
        "        })\n",
        "\n",
        "# âœ… Show what we got\n",
        "if results:\n",
        "    df = pd.DataFrame(results)\n",
        "    df = df.sort_values(\"ðŸ“… Date Filed\", ascending=False).reset_index(drop=True)\n",
        "    pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "    print(\"âœ… Here's what we found â€” latest at the top:\\n\")\n",
        "    display(df.head(30))\n",
        "else:\n",
        "    if keywords:\n",
        "        print(f\"ðŸ¤· No {form_filter} filings mentioning {', '.join(keywords)} in the last {days_back} days.\")\n",
        "    else:\n",
        "        print(f\"ðŸ¤· No {form_filter} filings found in the last {days_back} days.\")\n"
      ],
      "metadata": {
        "id": "Raz1zxjcgEPM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}